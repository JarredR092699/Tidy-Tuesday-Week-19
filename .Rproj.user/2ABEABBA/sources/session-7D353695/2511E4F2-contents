---
title: "Tidy Tuesday Tutorials"
author: "Jarred Robidoux"
date: "2023-05-10"
output:
  html_document: 
    toc: yes
    code_folding: show
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 
In this article, we will be diving deep into the Tidy Tuesday data for the week of May 9th, 2023. **Tidy Tuessday** a weekly data project in R, offers us a wealth of intriguing data to explore and analyze, and this week is no exception. 

Our main objective will be to demonstrate how to create a variety of compelling visualizations such as charts, graphs, and tables using this dataset. These visualizations will not only help us understand the data better but also illustrate how versatile and powerful tools like R can be when dealing with complex datasets. 

The data we'll be working with is intriguing and multifaceted, consisting of numerous columns each representing different variables. This complexitiy offers us a wide range of potential analysis directions and questions to answer. 

If you're interested in exploring this dataset yourself, I strongly encourage you to follow [this link](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-05-09/readme.md) where you can find a comprehensive breakdown of the columns and what they represent in this dataset. 

Let's get started! 

## Loading Packages 
Before we embark on our quest to extract meaningful insights from our Tidy Tuesday data, let's ensure we have all the necessary tools loaded into our R environment, setting the stage for the exciting data exploration to follow. 
```{r, warning = FALSE}
# install.packages("tidyverse")
library(tidyverse)
# install.packages("ggplot2")
library(ggplot2)
# install.packages("tidytuesdayR")
library(tidytuesdayR)
# install.packages("janitor")
library(janitor)
# install.packages("ggthemes")
library(ggthemes)
# install.packages("gh")
library(gh)
# install.packages("cowplot")
library(cowplot)
# install.packages("ggridges")
library(ggridges)
```

## Generate PAT token
Sometimes you may hit an API limit for GitHub. GitHub imposes a rate limit on the number of requests that can be made to its API within a certain timeframe. This is to prevent abuse and ensure fair usage. 

If you run into an error that looks like this: 

Only -1 Github queries remaining until 2023-05-10 10:28:16 AM EDT.
Error in github_sha(file.path("data", tt_year, tt_date), auth = auth) : 
  Response Code 403: API rate limit exceeded for 66.194.199.251. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)

Then you should follow these steps to generate a new PAT token through GitHub: 

1. Go to GitHub and log in: Enter your GitHub account credentials and log into your account.

2. Open the settings menu: Click on your profile picture in the upper right corner of the GitHub homepage. A drop-down menu should appear. Click on the "Settings" option.

3. Open the Developer Settings: Scroll down to the bottom of the settings sidebar and click on "Developer settings".

4. Open the Personal Access Tokens: Click on "Personal access tokens" which is located in the left sidebar of the Developer Settings page.

5. Generate a new token: Click on the "Generate new token" button. You'll be asked to confirm your password before you can proceed.

6. Choose your settings: Give your token a descriptive name and select the scopes (or permissions) you want this token to have. If you're just using this token for accessing Tidy Tuesday data, you probably don't need to select any scopes.

7. Generate the token: Click the "Generate token" button at the bottom of the page.

8. Copy your new token: After you click "Generate token", GitHub will take you to a new page that shows your token. Make sure to copy the token now and store it somewhere safe, because once you navigate away from this page, GitHub won't show you this token again.

Remember, the PAT is like a password. Do not share it publicly or post it in public repositories. Treat it with the same confidentiality as you would your password.

In your R scripts, you can use the PAT to increase your rate limit by using the gh_pat() function from the gh package. You can set this in your R environment file or within your script. Remember, don't share scripts that include your personal access token.

Here's an example of how you might use the gh_pat() function:
```{r}
# Load the gh package
library(gh)

# Set your PAT
# Sys.setenv(GITHUB_PAT = "your_personal_access_token")
```

Now you can make requests with a higher rate limit
Replace "your_personal_access_token_here" with the PAT you just created. Be sure to keep the quotes around the PAT.


## Loading Data
The **tidytuesdayR** package has some great functionality when it comes to loading in the data from each week. Here, we will use the *tt_load()* function to load our data for the week. 

There's two ways we can do this: 

1. Using the ISO 8601 date: This format, allows for precise and unambiguous representation. This can be particularly useful when working with datasets spanning across different years.  

2. Using the week number: This alternative approach can be quite handy if you're familiar with the week number throughout the year. 
 
I'll demonstrate how to utilize both these methods below:
```{r}
# ISO 8601
tidytues_data <- tt_load("2023-05-09")

# Week Number 
# tidytues_data2 <- tt_load(2023, week = 19)
```
It is important to mention that if you choose to use the week number route, you still need to specify the year! 

We've loaded our data into our R environment, but there are two seperate files that were loaded in so we need to create an object for each one. Luckily, we can use the **$** here to specify which dataset we want from our larger **tidytues_data** object. 
```{r}
# Create childcare_costs object 
childcare_costs <- tidytues_data$childcare_costs

# Create counties object 
counties <- tidytues_data$counties
```

Now that we've separated our data into two different objects, let's take a look at the data types, and names of the columns in each dataset. 
```{r}
# childcare_costs
glimpse(childcare_costs)
colnames(childcare_costs)

# counties 
glimpse(counties)
colnames(counties)
```
Looks like our **childcare_costs** dataset has a large amount of numeric data, and our **counties** dataset has some categorical variables like *county_name* and *state_name*

## Joining Data
To facilitate our analysis, we'll combine our datasets using the **'county_fips_code'** as the common key. This aligns all our relevant data in a single dataframe, paving the way for more straightforward exploration and manipulation. 

In this instance we're employing the **left_join()** function because we want to maintain all data from **counties** dataset (x), and incorporate corresponding records from the **childcare_costs** dataset. 

For those unfamilar with join operations in R, they essentially allow us to combine two datasets based on a common variable. The link provided [here](https://www.datasciencemadesimple.com/join-in-r-merge-in-r/) offers a comprehensive explanation. 
```{r}
joined_data <- left_join(counties, childcare_costs, by = ("county_fips_code"))
```

Now that we've joined our data together, let's make sure everything looks good. 
```{r}
head(joined_data)
```

Things looks good! Now it's time for the fun stuff! 

# Exploratory Analysis 
Our newly combined dataset **joined_data**, contains census like data such as unemployment rate, poverty rate, median househould income, racial population, and jobs data. 

## Median Household Income in PA (2018)
Let's take a look at the median household income strictly within the state of PA for the year of 2018.   
```{r}
pa_mhi <- joined_data %>% 
  # filter the data to only include counties in PA
  filter(state_abbreviation == "PA", study_year == 2018) %>% 
  # arrange the data from largest to smallest median home income 
  arrange(desc(mhi_2018)) %>% 
  # select the top 20 counties in the state
  top_n(20)
```
We have segmented that data we want to visualize using tools from the **dplyr** package, now it's time to use some **ggplot2**

### Creating a Lollipop Chart
Referencing the [R Graph Gallery](https://r-graph-gallery.com/301-custom-lollipop-chart.html) we are going to create a lollipop chart of the median household income in PA during 2018. 
```{r}
# Use our segmented data frame 
pa_mhi_plot <- pa_mhi %>% 
  # send object into ggplot
  ggplot(aes(x=reorder(county_name, mhi_2018), y=mhi_2018))+
  # geom_segment() draws the lines
  geom_segment(aes(xend=reorder(county_name, -mhi_2018), y=0, yend = mhi_2018), color = 'skyblue')+
  # geom_point() adds the point at the end of each county
  geom_point(color = "blue", size = 3, alpha = 0.6)+
  # This edits the values of our y axis
  scale_y_continuous(limits = c(0, max(pa_mhi$mhi_2018)*1.1), expand=c(0,0))+
  # flips our chart so it is shown horizontally instead of vertically
  coord_flip()+
  theme(
    text = element_text(size = 12, color = "gray15"),
    title = element_text(size = 16),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.background = element_rect(fill = "floralwhite"),
    plot.background = element_rect(fill = "floralwhite"),
    axis.text.y = element_text(face = "bold", color = "black"),
    axis.text.x = element_text(face = "bold", color = "black"),
    plot.title = element_text(hjust = 0.5), 
    plot.subtitle = element_text(hjust = 0.5)
  )+
  labs(
    title = "Median Household Income in Pennsylvania (2018)",
    subtitle = "Top 20 Counties"
  )+
  xlab("County Name")+
  ylab("Median Household Income (2018)")

pictured_plot <- ggdraw(pa_mhi_plot)+
  draw_image("https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Flag_of_Pennsylvania.svg/1280px-Flag_of_Pennsylvania.svg.png", height = .25, x = 0.30, y = 0.2)


# Save our plot to our computer using ggsave()
ggsave("pa_median_household_income.png", pictured_plot, dpi = 300, height = 10, width = 20, units = "in")
```
Lollipop charts are sometimes a better option than bar charts when you want to display categorical variables vs continuous variables. 

## Unemployment Rates for the state of Ohio
Next, let's look at the overall employment rates for the state of Ohio from 2008 to 2018. 


### Creating a Ridgeline Plot 
Our next plot we will create is called a **ridgeline** plot, which displays the distribution of a numeric variable for several groups. In this example, we will take a look at the unemployment rate for all counties in Ohio. 
```{r}
# Segment the data
ohio_unemployment <- joined_data %>%
  # filter only states with the abbreviation "OH"
  filter(state_abbreviation == "OH") %>% 
  # group by study_year so that we can grab the average unemployment rate per year
  group_by(study_year)
```
Now that our data is segmented we can create a ridgeline plot
```{r}
# Convert study_year to a factor 
ohio_unemployment$study_year <- as.factor(ohio_unemployment$study_year)

# Check to make sure this worked 
str(ohio_unemployment)

ohio_chart <- ohio_unemployment %>% 
  ggplot(aes(x=unr_16, y=study_year, fill = study_year))+
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01)+
  theme_ridges()+
  theme(
    legend.position = "none", 
    text = element_text(size = 12, color = "gray15"),
    title = element_text(size = 16),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.background = element_rect(fill = "floralwhite"),
    plot.background = element_rect(fill = "floralwhite"),
    axis.text.y = element_text(face = "bold", color = "black"),
    axis.text.x = element_text(face = "bold", color = "black"),
    plot.title = element_text(hjust = 0.5), 
    plot.subtitle = element_text(hjust = 0.5),
    axis.title.x = element_text(hjust = 0.5),
    axis.title.y = element_text(hjust = 0.5)
  )+
    labs(
    title = "Distribution of Unemployment in Ohio",
    subtitle = "Unemployment for population 16+ years old"
  )+
  xlab("% of Unemployment")+
  ylab("Year")

ohio_chart
```
The **ridgeline** chart is a powerful tool for visualizing changes in distributions over time or across categories. In this case we're using it to examine the distribution of unemployment rates in different years. 

Each *ridge* in the chart represents a year, and the shape of the ridge shows the distribution of unemployment rates for that year. The wider parts of a ridge indicate where most of the unemployment rates fall, and the narrower parts indicate less common unemployment rates. 

## 





